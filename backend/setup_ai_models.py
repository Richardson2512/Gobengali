#!/usr/bin/env python3
"""
Quick setup script to download and configure AI models for GoBengali
Run with: python setup_ai_models.py
"""

import os
import sys
from pathlib import Path

def check_requirements():
    """Check if required packages are installed"""
    print("üîç Checking requirements...")
    required_packages = [
        'transformers',
        'torch',
        'sentencepiece',
        'symspellpy',
        'langdetect'
    ]
    
    missing = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"  ‚úì {package}")
        except ImportError:
            print(f"  ‚úó {package} (missing)")
            missing.append(package)
    
    if missing:
        print(f"\n‚ùå Missing packages: {', '.join(missing)}")
        print(f"\nüí° Install with: pip install -r requirements-ai-models.txt")
        return False
    
    print("‚úÖ All requirements satisfied!\n")
    return True

def download_models():
    """Download AI models"""
    print("üì• Downloading AI models (this will take 5-15 minutes)...\n")
    
    try:
        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM
        
        models = [
            {
                "name": "Translation (NLLB-200)",
                "id": "facebook/nllb-200-distilled-600M",
                "size": "1.2GB",
                "type": "seq2seq"
            },
            {
                "name": "Grammar (IndicBERT)",
                "id": "ai4bharat/IndicBERTv2-MLM-only",
                "size": "560MB",
                "type": "mlm"
            }
        ]
        
        cache_dir = "./models"
        os.makedirs(cache_dir, exist_ok=True)
        
        for model_info in models:
            print(f"\nüì¶ Downloading {model_info['name']} ({model_info['size']})...")
            print(f"   Model ID: {model_info['id']}")
            
            try:
                # Download tokenizer
                print("   ‚è≥ Downloading tokenizer...")
                tokenizer = AutoTokenizer.from_pretrained(
                    model_info['id'],
                    cache_dir=cache_dir
                )
                print("   ‚úì Tokenizer downloaded")
                
                # Download model
                print("   ‚è≥ Downloading model...")
                if model_info['type'] == 'seq2seq':
                    model = AutoModelForSeq2SeqLM.from_pretrained(
                        model_info['id'],
                        cache_dir=cache_dir
                    )
                else:
                    model = AutoModelForMaskedLM.from_pretrained(
                        model_info['id'],
                        cache_dir=cache_dir
                    )
                print(f"   ‚úì {model_info['name']} downloaded successfully!")
                
                del model
                del tokenizer
                
            except Exception as e:
                print(f"   ‚ùå Failed to download {model_info['name']}: {e}")
                return False
        
        print("\n‚úÖ All models downloaded successfully!")
        print(f"üìÅ Models cached in: {os.path.abspath(cache_dir)}")
        return True
        
    except ImportError as e:
        print(f"‚ùå Error importing transformers: {e}")
        print("üí° Install with: pip install transformers torch")
        return False

def create_bengali_dictionary():
    """Create a basic Bengali dictionary for spell checking"""
    print("\nüìù Creating Bengali dictionary...")
    
    dict_file = "bengali_dictionary.txt"
    
    if os.path.exists(dict_file):
        print(f"  ‚ÑπÔ∏è  Dictionary already exists: {dict_file}")
        return True
    
    # Basic Bengali word frequency list
    words = """‡¶Ü‡¶Æ‡¶ø 10000
‡¶§‡ßÅ‡¶Æ‡¶ø 8000
‡¶∏‡ßá 8000
‡¶Ü‡¶Æ‡¶∞‡¶æ 7000
‡¶§‡ßã‡¶Æ‡¶∞‡¶æ 6000
‡¶§‡¶æ‡¶∞‡¶æ 6000
‡¶è‡¶á 9000
‡¶∏‡ßá‡¶á 7000
‡¶ï‡¶ø 9000
‡¶ï‡ßá 8000
‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º 6000
‡¶ï‡¶ñ‡¶® 6000
‡¶ï‡ßá‡¶® 7000
‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá 6000
‡¶Ü‡¶õ‡ßá 9000
‡¶õ‡¶ø‡¶≤ 8000
‡¶π‡¶¨‡ßá 8000
‡¶ï‡¶∞‡¶õ‡ßá 7000
‡¶ï‡¶∞‡ßá‡¶õ‡ßá 7000
‡¶ï‡¶∞‡¶¨‡ßá 7000
‡¶¨‡¶≤‡¶õ‡ßá 6000
‡¶¨‡¶≤‡ßá‡¶õ‡ßá 6000
‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡ßá 6000
‡¶Ø‡¶æ‡¶¨‡ßá 6000
‡¶Ü‡¶∏‡¶õ‡ßá 6000
‡¶Ü‡¶∏‡¶¨‡ßá 6000
‡¶¶‡ßá‡¶ñ‡¶õ‡ßá 6000
‡¶¶‡ßá‡¶ñ‡ßá‡¶õ‡ßá 6000
‡¶≠‡¶æ‡¶≤‡ßã 8000
‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ 6000
‡¶¨‡¶°‡¶º 7000
‡¶õ‡ßã‡¶ü 6000
‡¶®‡¶§‡ßÅ‡¶® 7000
‡¶™‡ßÅ‡¶∞‡¶æ‡¶§‡¶® 5000
‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ 7000
‡¶¨‡¶á 7000
‡¶ï‡¶≤‡¶Æ 6000
‡¶ï‡¶æ‡¶ó‡¶ú 6000
‡¶ü‡ßá‡¶¨‡¶ø‡¶≤ 5000
‡¶ö‡ßá‡¶Ø‡¶º‡¶æ‡¶∞ 5000
‡¶ò‡¶∞ 7000
‡¶¶‡¶∞‡¶ú‡¶æ 6000
‡¶ú‡¶æ‡¶®‡¶æ‡¶≤‡¶æ 5000
‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑ 8000
‡¶õ‡ßá‡¶≤‡ßá 7000
‡¶Æ‡ßá‡¶Ø‡¶º‡ßá 7000
‡¶¨‡¶æ‡¶¨‡¶æ 7000
‡¶Æ‡¶æ 8000
‡¶≠‡¶æ‡¶á 7000
‡¶¨‡ßã‡¶® 7000
‡¶¨‡¶®‡ßç‡¶ß‡ßÅ 7000
‡¶∏‡ßç‡¶ï‡ßÅ‡¶≤ 7000
‡¶ï‡¶≤‡ßá‡¶ú 6000
‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º 6000
‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï 6000
‡¶õ‡¶æ‡¶§‡ßç‡¶∞ 7000
‡¶™‡¶∞‡ßÄ‡¶ï‡ßç‡¶∑‡¶æ 7000
‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ 9000
‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø 7000
‡¶ó‡¶£‡¶ø‡¶§ 6000
‡¶¨‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶® 6000
‡¶¢‡¶æ‡¶ï‡¶æ 8000
‡¶ï‡¶≤‡¶ï‡¶æ‡¶§‡¶æ 7000
‡¶≠‡¶æ‡¶∞‡¶§ 8000
‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂ 9000
‡¶§‡¶ø‡¶®‡¶∂ 5000
‡¶∏‡¶∞‡¶ï‡¶æ‡¶∞ 7000
‡¶õ‡¶ø‡¶≤‡ßã 6000
‡¶ï‡¶∞‡¶õ‡ßá‡¶® 6000
‡¶¨‡¶≤‡¶õ‡ßá‡¶® 5000"""
    
    try:
        with open(dict_file, 'w', encoding='utf-8') as f:
            f.write(words)
        print(f"  ‚úì Dictionary created: {dict_file}")
        print(f"  üìä Contains {len(words.split(chr(10)))} words")
        return True
    except Exception as e:
        print(f"  ‚ùå Failed to create dictionary: {e}")
        return False

def create_env_file():
    """Create .env file with model configuration"""
    print("\n‚öôÔ∏è  Creating .env configuration...")
    
    env_file = ".env"
    
    if os.path.exists(env_file):
        print(f"  ‚ÑπÔ∏è  .env file already exists")
        return True
    
    env_content = """# GoBengali AI Model Configuration

# Model Settings
USE_GPU=false
MODEL_CACHE_DIR=./models

# AI Models
TRANSLATION_MODEL=facebook/nllb-200-distilled-600M
GRAMMAR_MODEL=ai4bharat/IndicBERTv2-MLM-only

# Set USE_GPU=true if you have NVIDIA GPU with CUDA
# For larger models (better accuracy but slower):
# TRANSLATION_MODEL=facebook/nllb-200-distilled-1.3B

# API Settings
DEBUG=true
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:3001
"""
    
    try:
        with open(env_file, 'w') as f:
            f.write(env_content)
        print(f"  ‚úì Configuration created: {env_file}")
        return True
    except Exception as e:
        print(f"  ‚ùå Failed to create .env: {e}")
        return False

def main():
    """Main setup function"""
    print("=" * 60)
    print("ü§ñ GoBengali AI Models Setup")
    print("=" * 60)
    print()
    
    # Check requirements
    if not check_requirements():
        sys.exit(1)
    
    # Create configuration
    create_env_file()
    
    # Create dictionary
    create_bengali_dictionary()
    
    # Download models
    print("\n" + "=" * 60)
    response = input("üì• Download AI models now? (2-3GB, ~10 minutes) [y/N]: ")
    
    if response.lower() in ['y', 'yes']:
        if download_models():
            print("\n" + "=" * 60)
            print("‚úÖ Setup Complete!")
            print("=" * 60)
            print("\nüöÄ Next steps:")
            print("   1. Run: python main.py")
            print("   2. API will be available at: http://localhost:8000")
            print("   3. Test with: http://localhost:8000/health")
            print()
        else:
            print("\n‚ùå Model download failed")
            sys.exit(1)
    else:
        print("\n‚è≠Ô∏è  Skipping model download")
        print("üí° Models will be downloaded automatically on first API call")
        print("üöÄ You can now run: python main.py")
        print()

if __name__ == "__main__":
    main()

